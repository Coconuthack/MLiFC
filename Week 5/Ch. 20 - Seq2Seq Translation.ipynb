{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch. 20 - Simple Seq2Seq\n",
    "\n",
    "Welcome to week 5. You now already have a solid foundation and know the most important pieces of modern deep neural networks. In the next few weeks, you will gain practical knowledge of advanced models. You will find them much more compute intensive and more difficult to work with than the classifiers we looked at so far. But you will also recognize their ability to perform tasks that until very recently were science fiction. We will dive in head first with a sequence to sequence model that can translate English to French. \n",
    "\n",
    "## Translation\n",
    "In 2016, Google announced that it had replaced the entire google translate algorithm with a [single neural network](https://research.google.com/pubs/pub45610.html). The special thing about the [Google Neural Machine Translation](https://en.wikipedia.org/wiki/Google_Neural_Machine_Translation) system is that it translates many languages 'end to end' using only a single model. It works by [encoding the semantics of a sentence and then decoding the semantics into the desired output language](https://research.googleblog.com/2016/11/zero-shot-translation-with-googles.html). The fact that such a system is possible at all baffled many linguists and other researchers as it shows that machine learning can create systems that accurately capture high level meanings and semantics without being given any explicit rules. These semantic meanings are represented as an encoding vector and while we don't quite yet know how to interpret these vectors there are sure a lot of useful applications for them. Translating from one language to another is popular, but we could use a similar approach to 'translate' a report into a summary. In this chapter we will follow a similar approach but train a much simpler model that can only translate from English to French. We will use this task to demo a simple sequence to sequence (Seq2Seq) model. \n",
    "\n",
    "## Overview\n",
    "\n",
    "If all phrases had the exact same length, we could simply use an LSTM (or multiple). Remember that an LSTM can also return a full sequence of the same length as the input sequence. However, in many cases sequences will not have the same length. To deal with different lengths of phrases, we first create an encoder which aims to capture the sentences semantic meaning. We then create a decoder, which has two inputs: The encoded semantics and the sequence that was already produced. The decoder then predicts the next item in the sequence. For our character level translator this looks like this:\n",
    "\n",
    "![Overview](./assets/seq2seq_overview.png)\n",
    "\n",
    "\n",
    "Note how the output of the decoder is used as the input of the decoder again. This process is only stopped once the decoder produces a < STOP > tag that indicates that the sequence is over.\n",
    "\n",
    "\n",
    "## The data\n",
    "We use a dataset of English phrases and their Translation. We implement this model on a character level, which means we won't tokenize words as in previous models but characters. This makes the task harder for our network because it now also has to learn how to spell words! But on the other hand there are much less characters than words so we can just one hot encode characters and don't have to work with embeddings. This makes our model a bit simpler. Without much further ado, let's load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 10000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "data_path = 'fra-eng/fra.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input (English) and target (French) is tab delimited in the data file. Each row represents a new phrase. The translations are separated by a tab [(escaped character: \\t)](https://docs.python.org/2.0/ref/strings.html). So we loop over the lines and read out inputs and targets by splitting the lines at the tab symbol.\n",
    "\n",
    "To build up our tokenizer, we also need to know which characters are present in our dataset. So for all characters we check whether they are already in our [set of seen characters](https://docs.python.org/2/library/sets.html) and if not add them to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "# Loop over lines\n",
    "lines = open(data_path).read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    # Input and target are split by tabs\n",
    "    # English TAB French\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    \n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    \n",
    "    # Create a set of all unique characters in the input\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "            \n",
    "    # Create a set of all unique output characters\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "print('Number of samples:', len(input_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build up our tokenizer. While this could be done with the Keras tokenizer, we will just do it manually here. Note that we build a different tokenizer for input and output, as some characters might appear in French but not in English and the other way around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique input tokens: 71\n",
      "Number of unique output tokens: 93\n"
     ]
    }
   ],
   "source": [
    "input_characters = sorted(list(input_characters)) # Make sure we achieve the same order in our input chars\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters) # aka size of the english alphabet + numbers, signs, etc.\n",
    "num_decoder_tokens = len(target_characters) # aka size of the french alphabet + numbers, signs, etc.\n",
    "\n",
    "\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works very similar to a tokenizer\n",
    "# The index maps a character to a number\n",
    "input_token_index = {char: i for i, char in enumerate(input_characters)}\n",
    "target_token_index = {char: i for i, char in enumerate(target_characters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 51 48 0 46 44 63 0 62 52 63 62 0 58 57 0 63 51 48 0 56 44 63 "
     ]
    }
   ],
   "source": [
    "# Demo character tokenization\n",
    "for c in 'the cat sits on the mat':\n",
    "    print(input_token_index[c], end = ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build up our model training data. Remember that our model has two inputs but one output. While our model can handle sequences of any length, it is handy to prepare the data in Numpy and thus to know how long our longest sequence is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length for inputs: 16\n",
      "Max sequence length for outputs: 59\n"
     ]
    }
   ],
   "source": [
    "max_encoder_seq_length = max([len(txt) for txt in input_texts]) # Get longest sequences length\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we prepare input and output data for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoder_input_data is a 3D array of shape (num_pairs, max_english_sentence_length, num_english_characters) \n",
    "# containing a one-hot vectorization of the English sentences.\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "# decoder_input_data is a 3D array of shape (num_pairs, max_french_sentence_length, num_french_characters) \n",
    "# containg a one-hot vectorization of the French sentences.\n",
    "\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "# decoder_target_data is the same as decoder_input_data but offset by one timestep. \n",
    "# decoder_target_data[:, t, :] will be the same as decoder_input_data[:, t + 1, :]\n",
    "\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the input and output of the decoder is the same except that the output is one timestep ahead. This makes sense when you consider that we will feed an unfinished sequence into the decoder and want it to predict the next character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loop over input texts\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    # Loop over each char in an input text\n",
    "    for t, char in enumerate(input_text):\n",
    "        # Create one hot encoding by setting the index to 1\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    # Loop over each char in the output text\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model - Keras functional API\n",
    "\n",
    "The avid reader will wonder how we create a model with two inputs. After all, all our models so far had one input, one output and nothing more. Enter the [Keras functional API](https://keras.io/getting-started/functional-api-guide/). So far, we used [Sequential models](https://keras.io/getting-started/sequential-model-guide/). In the Sequential model, layers get stacked on top of each other when we call ``model.add()``. In the functional API, we have a bit more control and can specify how layers should be connected. Let's look at a simply two layer network in both the Sequential and functional way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 4,420\n",
      "Trainable params: 4,420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequential model:\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 4,420\n",
      "Trainable params: 4,420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Functional API\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Input # Note that input is a layer now too\n",
    "\n",
    "model_input = Input(shape=(64,))\n",
    "x = Dense(64)(model_input)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(4)(x)\n",
    "model_output = Activation('softmax')(x)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the functional API can connect layers in more advanced ways than the Sequential model. We can also separate the layer creation and connection step. Note however, that once a layer is connected, we can not reuse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 4,420\n",
      "Trainable params: 4,420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Functional API\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Input # Note that input is a layer now too\n",
    "\n",
    "model_input = Input(shape=(64,))\n",
    "dense = Dense(64)\n",
    "x = dense(model_input)\n",
    "activation = Activation('relu')\n",
    "x = activation(x)\n",
    "dense_2 = Dense(4)\n",
    "x = dense_2(x)\n",
    "model_output = Activation('softmax')(x)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the functional API to create a model with two inputs.\n",
    "\n",
    "Recall the info graphic from earlier:\n",
    "![Overview](./assets/seq2seq_overview.png)\n",
    "\n",
    "You see that the decoder also has two inputs: the decoder inputs and the encoded semantics. The encoded semantics however are not directly the outputs of the encoder LSTM but its _states_. In an LSTM, states are [the hidden memory of the cells](https://machinelearningmastery.com/return-sequences-and-return-states-for-lstms-in-keras/). What happens is that the first 'memory' of our decoder is the encoded semantics. To give the decoder this first memory, we can initialize its states with the states of the decoder LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens), name = 'encoder_inputs')\n",
    "\n",
    "# The return_state contructor argument, configuring a RNN layer to return a list \n",
    "# where the first entry is the outputs and the next entries are the internal RNN states. \n",
    "# This is used to recover the states of the encoder.\n",
    "encoder = LSTM(latent_dim, return_state=True, name = 'encoder')\n",
    "\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens), name = 'decoder_inputs')\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name = 'decoder_lstm')\n",
    "\n",
    "# The inital_state call argument, specifying the initial state(s) of a RNN. \n",
    "# This is used to pass the encoder states to the decoder as initial states.\n",
    "# Basically making the first memory of the decoder the encoded semantics\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name = 'decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     (None, None, 71)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     (None, None, 93)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (LSTM)                  [(None, 256), (None, 335872      encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 256),  358400      decoder_inputs[0][0]             \n",
      "                                                                 encoder[0][1]                    \n",
      "                                                                 encoder[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 93)     23901       decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 718,173\n",
      "Trainable params: 718,173\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model \n",
    "# NOTE: This code requires Graphviz and pydot to run\n",
    "# The output is also attached in markdown below\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model Vis](./assets/model_vis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to train the model. Use a GPU since this might take a while otherwise. Alternative you can also load the weights provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "# Save model\n",
    "model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('s2s.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating inference models\n",
    "\n",
    "For inference, we want a different model than for training. Encoding and decoding should now be separated into two different models. Luckily the functional API allows us to reuse the layers defined for another model and retain their trained weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define encoder model\n",
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define decoder model\n",
    "\n",
    "# Inputs from the encoder\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "\n",
    "# Create a combined memory to input into the decoder\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "# Predict next char\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# The model takes in the encoder memory plus it's own memory as an input and spits out \n",
    "# a prediction plus its own memory to be used for the next char\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating\n",
    "We can now start to use our model. First we create an index which maps tokens to characters again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = {i: char for char, i in input_token_index.items()}\n",
    "reverse_target_char_index = {i: char for char, i in target_token_index.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we translate a phrase, we now first encode the input. We then loop, feeding the decoder states back into the decoder until we receive a STOP (in our case we use the tab character to signal STOP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    # Loop untill we recieve a stop sign\n",
    "    while not stop_condition:\n",
    "        # Get output and internal states of the decoder \n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Get the predicted token (the token with the highest score)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        # Get the character belonging to the token\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        # Append char to output\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can translate English to French! At least for some phrases it works quite well. Given that we did not supply our model with any rules about French words or grammar this is quite impressive. Translation systems like Googles of course use much bigger datasets and models, but in principle it is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_text = 'Cheers!'\n",
    "placeholder = np.zeros((1,len(my_text)+10,num_encoder_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 C 21\n",
      "1 h 51\n",
      "2 e 48\n",
      "3 e 48\n",
      "4 r 61\n",
      "5 s 62\n",
      "6 ! 1\n"
     ]
    }
   ],
   "source": [
    "for i, char in enumerate(my_text):\n",
    "    print(i,char, input_token_index[char])\n",
    "    placeholder[0,i,input_token_index[char]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Santé !\\n'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence(placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this chapter you have learned the basics of Seq2Seq models and the functional API. You have built a sophisticated model that can translate English phrases to French. The concepts you learned in this chapter can be extended to for example text summarization."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
