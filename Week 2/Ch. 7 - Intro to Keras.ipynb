{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Keras\n",
    "In the last week we built a neural network from scratch using nothing but raw python and the matrix library numpy. While it is a great way to understand the inner workings of neural networks, it in not very practical to always implement your own learning algorithms from scratch. In fact, much of the progress in machine learning in recent years was archived because reliable, high performance and easy to use libraries where created. For the rest of the course we will be using [Keras](https://keras.io/). Keras is a high level neural network API that works on top of other deep learning libraries. We will be using Keras in combination with Googles [TensorFlow](https://www.tensorflow.org/), a very popular deep learning library. You can imagine Keras as a front end which you as a developer use while TensorFlow handles all the maths in the background. This setup allows us to harness the high performance of TensorFlow while at the same time iterating quickly with an easy to use API.\n",
    "\n",
    "## MNIST with Keras\n",
    "Perhaps the best way to understand how Keras works is by just getting started with it. Last weeks challenge was the MNIST dataset, a collection of hand written digits. In this introduction we are going to use the same dataset to get to know Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras offers two basic ways to build models, the [sequential model](https://keras.io/getting-started/sequential-model-guide/), in which layers are just stacked on top of each other and the [functional API](https://keras.io/getting-started/functional-api-guide/) that allows to create more complex structures. For most of the course we will be using the sequential model. As you also can see from the import statement, Keras is using TensorFlow as a back end. Next up we need to import some modules we use to create our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just imported the dense layer module and the activation function module. A dense layer is simply a layer in which every node is fully connected to all nodes from the previous layers. This was the case in all neural networks we have built so far but there are other possibilities, too. We will explore them later. Keras also provides a utility to directly load some common machine learning datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For onehot encoding we will continue to use SciKit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Generate one hot encoding\n",
    "\n",
    "# Reshape from array to vector\n",
    "y_train = y_train.reshape(y_train.shape[0],1)\n",
    "# Generate one hot encoding\n",
    "enc = OneHotEncoder()\n",
    "onehot = enc.fit_transform(y_train)\n",
    "# Convert to numpy vector\n",
    "y_train = onehot.toarray()\n",
    "\n",
    "# Reshape from array to vector\n",
    "y_test = y_test.reshape(y_test.shape[0],1)\n",
    "# Generate one hot encoding\n",
    "enc = OneHotEncoder()\n",
    "onehot = enc.fit_transform(y_test)\n",
    "# Convert to numpy vector\n",
    "y_test = onehot.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have to reshape the input X, which is a stack of matrices in the raw data into a stack of vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1] * X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] * X_test.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to build our model! We initialize the model building process like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now adding layers can be done with a simple ```.add()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the first layer we have to specify the input dimensions\n",
    "model.add(Dense(units=320, input_dim=784, activation='tanh'))\n",
    "\n",
    "model.add(Dense(units=160, activation='tanh'))\n",
    "\n",
    "model.add(Dense(units=10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to compile the model, turning it into a [static graph TensorFlow can execute](https://stackoverflow.com/questions/46154189/what-is-the-difference-of-static-computational-graphs-in-tensorflow-and-dynamic). In the compile statement we also get to specify things like the learning rate or whether we want to use some more advanced optimizer. If we do not specify a learning rate, Keras will choose a default value for us. We can also specify which metrics we want to track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there is only the training left to be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 10s - loss: 0.6398 - acc: 0.8955    \n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s - loss: 0.3837 - acc: 0.8903     \n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s - loss: 0.4106 - acc: 0.8768     \n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 9s - loss: 0.4231 - acc: 0.8718     \n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s - loss: 0.3797 - acc: 0.8849     \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.3593 - acc: 0.8905     \n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.3408 - acc: 0.8961     \n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s - loss: 0.3380 - acc: 0.8980     \n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.3259 - acc: 0.9005     \n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.3314 - acc: 0.8990     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1257ac550>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_train and y_train are Numpy arrays --just like in the Scikit-Learn API.\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will probably have noticed that this runs quite a bit faster than when we implemented our own neural network in numpy. That is because TensorFlow, which handles all the math operations is optimized for exactly these kinds of operations. Another advantage is that TensorFlow can run on a graphics processing unit (GPU). GPUs where originally invented to render computer game graphics, but it turned out that their architecture was ideal for deep learning. Much of deep learnings recent progress is owed to the fact that powerful GPUs and tools to use them for things other than graphics came on the market.\n",
    "\n",
    "To conclude this chapter we are going to evaluate our model with Keras evaluate function. It outputs an array of all metrics that are being kept track of, in our case the loss and the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.31037911518812178, 0.90590000000000004]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=X_test,y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "And thus concludes our brief introduction to Keras. To get more used to its sequential model, try implementing a different model for MNIST. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
